# Activation-functions-algorithm-and-code.
# This is a simple neural network for non linear data relationships.
# Using Activation functions.
The code can be like the forward propagation with tanh function.
Note :
The different between the forward propagation and activation functions is that we calculate the Hidden Layer using tanh (Value) and the final value will be closer to the 1.
